{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2018.csv.zip to /workspace/pyspark-airline-delay-classification\n",
      " 87%|███████████████████████████████████▋     | 207M/238M [00:00<00:00, 432MB/s]\n",
      "100%|█████████████████████████████████████████| 238M/238M [00:00<00:00, 420MB/s]\n",
      "Archive:  2018.csv.zip\n",
      "  inflating: 2018.csv                \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d sherrytp/airline-delay-analysis -f \"airline delay analysis/2018.csv\"\n",
    "!unzip 2018.csv.zip\n",
    "!rm 2018.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initlize pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"airline-delay-regression\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to make Jupyter work with Gitpod\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:==================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: double (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- TAXI_OUT: double (nullable = true)\n",
      " |-- WHEELS_OFF: double (nullable = true)\n",
      " |-- WHEELS_ON: double (nullable = true)\n",
      " |-- TAXI_IN: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_TIME: double (nullable = true)\n",
      " |-- ARR_DELAY: double (nullable = true)\n",
      " |-- CANCELLED: double (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: double (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: double (nullable = true)\n",
      " |-- AIR_TIME: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      " |-- CARRIER_DELAY: double (nullable = true)\n",
      " |-- WEATHER_DELAY: double (nullable = true)\n",
      " |-- NAS_DELAY: double (nullable = true)\n",
      " |-- SECURITY_DELAY: double (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: double (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read the data into a dataframe and print the schema\n",
    "df = spark.read.csv(\"2018.csv\", header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse datatype from schema. [Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py:279\u001b[0m, in \u001b[0;36mDataFrame.schema\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=277'>278</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=278'>279</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_schema \u001b[39m=\u001b[39m _parse_datatype_json_string(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mschema()\u001b[39m.\u001b[39mjson())\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=279'>280</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1314'>1315</a>\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1315'>1316</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1316'>1317</a>\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1317'>1318</a>\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1319'>1320</a>\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1320'>1321</a>\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1321'>1322</a>\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1015'>1016</a>\u001b[0m \u001b[39m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1016'>1017</a>\u001b[0m \u001b[39m   called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1017'>1018</a>\u001b[0m \u001b[39m   :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1033'>1034</a>\u001b[0m \u001b[39m if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1034'>1035</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1035'>1036</a>\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_connection()\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/java_gateway.py?line=1036'>1037</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py:281\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py?line=279'>280</a>\u001b[0m \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m connection\u001b[39m.\u001b[39msocket \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py?line=280'>281</a>\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_new_connection()\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py?line=281'>282</a>\u001b[0m \u001b[39mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py:288\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py?line=284'>285</a>\u001b[0m connection \u001b[39m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py?line=285'>286</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_parameters, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_parameters,\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py?line=286'>287</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_property, \u001b[39mself\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py?line=287'>288</a>\u001b[0m connection\u001b[39m.\u001b[39;49mconnect_to_java_server()\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py?line=288'>289</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_thread_connection(connection)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py:402\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py?line=399'>400</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context\u001b[39m.\u001b[39mwrap_socket(\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py?line=400'>401</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket, server_hostname\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_address)\n\u001b[0;32m--> <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py?line=401'>402</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket\u001b[39m.\u001b[39;49mconnect((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_address, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_port))\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/py4j/clientserver.py?line=402'>403</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket\u001b[39m.\u001b[39mmakefile(\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspace/pyspark-airline-delay-classification/regression.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfawazalesay-pysparkairl-ck4s7ekwcta/workspace/pyspark-airline-delay-classification/regression.ipynb#ch0000012vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfawazalesay-pysparkairl-ck4s7ekwcta/workspace/pyspark-airline-delay-classification/regression.ipynb#ch0000012vscode-remote?line=2'>3</a>\u001b[0m df\u001b[39m.\u001b[39;49mplot\u001b[39m.\u001b[39mscatter(x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFL_DATE\u001b[39m\u001b[39m'\u001b[39m, y\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mARR_DELAY\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1658\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1647'>1648</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1648'>1649</a>\u001b[0m     \u001b[39m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1649'>1650</a>\u001b[0m \n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1650'>1651</a>\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1655'>1656</a>\u001b[0m \u001b[39m    [Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1656'>1657</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1657'>1658</a>\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns:\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1658'>1659</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1659'>1660</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1660'>1661</a>\u001b[0m     jc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jdf\u001b[39m.\u001b[39mapply(name)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1215\u001b[0m, in \u001b[0;36mDataFrame.columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1203'>1204</a>\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1204'>1205</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcolumns\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1205'>1206</a>\u001b[0m     \u001b[39m\"\"\"Returns all column names as a list.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1206'>1207</a>\u001b[0m \n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1207'>1208</a>\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1212'>1213</a>\u001b[0m \u001b[39m    ['age', 'name']\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1213'>1214</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=1214'>1215</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [f\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mschema\u001b[39m.\u001b[39mfields]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py:281\u001b[0m, in \u001b[0;36mDataFrame.schema\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=278'>279</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_schema \u001b[39m=\u001b[39m _parse_datatype_json_string(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jdf\u001b[39m.\u001b[39mschema()\u001b[39m.\u001b[39mjson())\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=279'>280</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=280'>281</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=281'>282</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to parse datatype from schema. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=282'>283</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_schema\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse datatype from schema. [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# df.plot.scatter(x='FL_DATE', y='ARR_DELAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      "\n",
      "+----------+------+----+------------+---------+------------+----------------+--------+----+-----+---+\n",
      "|OP_CARRIER|ORIGIN|DEST|CRS_DEP_TIME|DEP_DELAY|CRS_ARR_TIME|CRS_ELAPSED_TIME|DISTANCE|YEAR|MONTH|DAY|\n",
      "+----------+------+----+------------+---------+------------+----------------+--------+----+-----+---+\n",
      "|        UA|   EWR| DEN|        1517|     -5.0|        1745|           268.0|  1605.0|2018|    1|  1|\n",
      "|        UA|   LAS| SFO|        1115|     -8.0|        1254|            99.0|   414.0|2018|    1|  1|\n",
      "|        UA|   SNA| DEN|        1335|     -5.0|        1649|           134.0|   846.0|2018|    1|  1|\n",
      "|        UA|   RSW| ORD|        1546|      6.0|        1756|           190.0|  1120.0|2018|    1|  1|\n",
      "|        UA|   ORD| ALB|         630|     20.0|         922|           112.0|   723.0|2018|    1|  1|\n",
      "+----------+------+----+------------+---------+------------+----------------+--------+----+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7096202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "df = df.drop(\"Unnamed: 27\", \"LATE_AIRCRAFT_DELAY\", \"SECURITY_DELAY\", \"NAS_DELAY\", \"WEATHER_DELAY\", \"CARRIER_DELAY\", \"AIR_TIME\", \"ACTUAL_ELAPSED_TIME\", \"DIVERTED\", \"CANCELLATION_CODE\", \"CANCELLED\", \"ARR_TIME\", \"TAXI_IN\", \"WHEELS_ON\", \"WHEELS_OFF\", \"TAXI_OUT\", \"DEP_TIME\", \"OP_CARRIER_FL_NUM\", \"ARR_DELAY\")\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "@udf(returnType=IntegerType())\n",
    "def get_month(date):\n",
    "    return int(date.split(\"-\")[1])\n",
    "\n",
    "@udf(returnType=IntegerType())\n",
    "def get_day(date):\n",
    "    return int(date.split(\"-\")[2])\n",
    "\n",
    "@udf(returnType=IntegerType())\n",
    "def get_year(date):\n",
    "    return int(date.split(\"-\")[0])\n",
    "\n",
    "# Adds month and a day column to the dataframe\n",
    "df = df.withColumn(\"YEAR\", get_year(df[\"FL_DATE\"]).cast(IntegerType()))\n",
    "df = df.withColumn(\"MONTH\", get_month(df[\"FL_DATE\"]).cast(IntegerType()))\n",
    "df = df.withColumn(\"DAY\", get_day(df[\"FL_DATE\"]).cast(IntegerType()))\n",
    "\n",
    "df = df.drop(\"FL_DATE\")\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "df.show(5)\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max categories: 358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Preparing the data\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "train, test = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Encode the categorical features using StringIndexer\n",
    "indexer = StringIndexer(inputCols=[\"OP_CARRIER\", \"ORIGIN\", \"DEST\", \"DAY\", \"MONTH\"], outputCols=[\"OP_CARRIER_INDEX\", \"ORIGIN_INDEX\", \"DEST_INDEX\", \"DAY_INDEX\", \"MONTH_INDEX\"])\n",
    "\n",
    "# Use one hot encoding to encode the categorical features\n",
    "encoder = OneHotEncoder(inputCols=[\"OP_CARRIER_INDEX\", \"ORIGIN_INDEX\", \"DEST_INDEX\", \"DAY_INDEX\", \"MONTH_INDEX\"], outputCols=[\"OP_CARRIER_VEC\", \"ORIGIN_VEC\", \"DEST_VEC\", \"DAY_VEC\", \"MONTH_VEC\"])\n",
    "\n",
    "# Create the assembler\n",
    "assembler = VectorAssembler(inputCols=[\"OP_CARRIER_VEC\", \"ORIGIN_VEC\", \"DEST_VEC\", \"CRS_DEP_TIME\", \"CRS_ARR_TIME\", \"DAY_VEC\", \"MONTH_VEC\", \"YEAR\"], outputCol=\"features\")\n",
    "\n",
    "# Get the maximum number of all categorical features in the dataframe\n",
    "num_of_origins = df.select(\"ORIGIN\").distinct().count()\n",
    "num_of_destinations = df.select(\"DEST\").distinct().count()\n",
    "num_of_carriers = df.select(\"OP_CARRIER\").distinct().count()\n",
    "max_num_of_categorical_features = max(num_of_origins, num_of_destinations, num_of_carriers)\n",
    "print(\"max categories:\", max_num_of_categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 44.274917223028034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"DEP_DELAY\", regParam=0.3)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[indexer, encoder, assembler, lr])\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Print the RMSE\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"DEP_DELAY\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 9.93221958518358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std: 44.739548581249586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\", test.select(\"DEP_DELAY\").agg({\"DEP_DELAY\": \"mean\"}).collect()[0][0])\n",
    "print(\"Std:\", test.select(\"DEP_DELAY\").agg({\"DEP_DELAY\": \"stddev\"}).collect()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model: Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression Model\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"DEP_DELAY\", maxDepth=5, maxBins=max_num_of_categorical_features)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[indexer, encoder, assembler, dtr])\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Print the RMSE\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"DEP_DELAY\", metricName=\"rmse\")\n",
    "print(\"RMSE (Decision Tree Regression):\", evaluator.evaluate(predictions))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
