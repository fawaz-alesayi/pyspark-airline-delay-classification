{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2018.csv.zip to /workspace/pyspark-airline-delay-classification\n",
      " 94%|█████████████████████████████████████▊  | 225M/238M [00:05<00:00, 32.0MB/s]\n",
      "100%|████████████████████████████████████████| 238M/238M [00:05<00:00, 43.3MB/s]\n",
      "Archive:  2018.csv.zip\n",
      "  inflating: 2018.csv                \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d sherrytp/airline-delay-analysis -f \"airline delay analysis/2018.csv\"\n",
    "!unzip 2018.csv.zip\n",
    "!rm 2018.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Picked up JAVA_TOOL_OPTIONS:  -Xmx3435m\n",
      "Picked up JAVA_TOOL_OPTIONS:  -Xmx3435m\n",
      "22/05/13 18:33:06 WARN Utils: Your hostname, fawazalesay-pysparkairl-ck4s7ekwcta resolves to a loopback address: 127.0.0.1; using 10.0.5.2 instead (on interface ceth0)\n",
      "22/05/13 18:33:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/13 18:33:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/13 18:33:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/05/13 18:33:07 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# initlize pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"airline-delay-regression\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to make Jupyter work with Gitpod\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:==================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: double (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- TAXI_OUT: double (nullable = true)\n",
      " |-- WHEELS_OFF: double (nullable = true)\n",
      " |-- WHEELS_ON: double (nullable = true)\n",
      " |-- TAXI_IN: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_TIME: double (nullable = true)\n",
      " |-- ARR_DELAY: double (nullable = true)\n",
      " |-- CANCELLED: double (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: double (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: double (nullable = true)\n",
      " |-- AIR_TIME: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      " |-- CARRIER_DELAY: double (nullable = true)\n",
      " |-- WEATHER_DELAY: double (nullable = true)\n",
      " |-- NAS_DELAY: double (nullable = true)\n",
      " |-- SECURITY_DELAY: double (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: double (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read the data into a dataframe and print the schema\n",
    "df = spark.read.csv(\"2018.csv\", header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_DELAY: double (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      " |-- MONTH: string (nullable = true)\n",
      " |-- DAY: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_DELAY: double (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      " |-- MONTH: string (nullable = true)\n",
      " |-- DAY: string (nullable = true)\n",
      "\n",
      "+----------+----------+------+----+------------+---------+------------+---------+----------------+--------+-----+---+\n",
      "|   FL_DATE|OP_CARRIER|ORIGIN|DEST|CRS_DEP_TIME|DEP_DELAY|CRS_ARR_TIME|ARR_DELAY|CRS_ELAPSED_TIME|DISTANCE|MONTH|DAY|\n",
      "+----------+----------+------+----+------------+---------+------------+---------+----------------+--------+-----+---+\n",
      "|2018-01-01|        UA|   EWR| DEN|        1517|     -5.0|        1745|    -23.0|           268.0|  1605.0|   01| 01|\n",
      "|2018-01-01|        UA|   LAS| SFO|        1115|     -8.0|        1254|    -24.0|            99.0|   414.0|   01| 01|\n",
      "|2018-01-01|        UA|   SNA| DEN|        1335|     -5.0|        1649|    -13.0|           134.0|   846.0|   01| 01|\n",
      "|2018-01-01|        UA|   RSW| ORD|        1546|      6.0|        1756|     -2.0|           190.0|  1120.0|   01| 01|\n",
      "|2018-01-01|        UA|   ORD| ALB|         630|     20.0|         922|     14.0|           112.0|   723.0|   01| 01|\n",
      "+----------+----------+------+----+------------+---------+------------+---------+----------------+--------+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "df = df.drop(\"Unnamed: 27\", \"LATE_AIRCRAFT_DELAY\", \"SECURITY_DELAY\", \"NAS_DELAY\", \"WEATHER_DELAY\", \"CARRIER_DELAY\", \"AIR_TIME\", \"ACTUAL_ELAPSED_TIME\", \"DIVERTED\", \"CANCELLATION_CODE\", \"CANCELLED\", \"ARR_TIME\", \"TAXI_IN\", \"WHEELS_ON\", \"WHEELS_OFF\", \"TAXI_OUT\", \"DEP_TIME\", \"OP_CARRIER_FL_NUM\")\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def get_month(date):\n",
    "    return date.split(\"-\")[1]\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def get_day(date):\n",
    "    return date.split(\"-\")[2]\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def get_year(date):\n",
    "    return date.split(\"-\")[0]\n",
    "\n",
    "# Adds month and a day column to the dataframe\n",
    "df = df.withColumn(\"YEAR\", get_year(df[\"FL_DATE\"]))\n",
    "df = df.withColumn(\"MONTH\", get_month(df[\"FL_DATE\"]))\n",
    "df = df.withColumn(\"DAY\", get_day(df[\"FL_DATE\"]))\n",
    "\n",
    "df.drop(\"FL_DATE\")\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
