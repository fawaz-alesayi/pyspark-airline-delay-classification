{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Dataset from Kaggle https://www.kaggle.com/usdot/flight-delays\n",
    "\n",
    "## Description\n",
    "The U.S. Department of Transportation's (DOT) Bureau of Transportation Statistics tracks the on-time performance of domestic flights operated by large air carriers. Summary information on the number of on-time, delayed, canceled, and diverted flights is published in DOT's monthly Air Travel Consumer Report and in this dataset of 2015 flight delays and cancellations.\n",
    "\n",
    "### Schema\n",
    "- |-- YEAR: integer (nullable = true) - The year of the flight\n",
    "- |-- MONTH: integer (nullable = true) - The month of the flight\n",
    "- |-- DAY: integer (nullable = true) - The day of the flight\n",
    "- |-- DAY_OF_WEEK: integer (nullable = true) - The day of the week of the flight\n",
    "- |-- AIRLINE: string (nullable = true) - The airline code of the flight\n",
    "- |-- FLIGHT_NUMBER: integer (nullable = true) - The flight number of the flight\n",
    "- |-- TAIL_NUMBER: string (nullable = true) - the tail number of the aircraft\n",
    "- |-- ORIGIN_AIRPORT: string (nullable = true) - The origin airport code of the flight\n",
    "- |-- DESTINATION_AIRPORT: string (nullable = true) - The destination airport code of the flight\n",
    "- |-- SCHEDULED_DEPARTURE: integer (nullable = true) - The scheduled departure time of the flight\n",
    "- |-- DEPARTURE_TIME: integer (nullable = true) - The actual departure time of the flight\n",
    "- |-- DEPARTURE_DELAY: integer (nullable = true) - The departure delay of the flight\n",
    "- |-- TAXI_OUT: integer (nullable = true) - The taxi out time of the flight\n",
    "- |-- WHEELS_OFF: integer (nullable = true) - The wheels off time of the flight\n",
    "- |-- SCHEDULED_TIME: integer (nullable = true) - The scheduled time of the flight\n",
    "- |-- ELAPSED_TIME: integer (nullable = true) - The elapsed time of the flight\n",
    "- |-- AIR_TIME: integer (nullable = true) - The air time of the flight\n",
    "- |-- DISTANCE: integer (nullable = true) - The distance between the origin and destination airports\n",
    "- |-- WHEELS_ON: integer (nullable = true) - The wheels on time of the flight\n",
    "- |-- TAXI_IN: integer (nullable = true) - The taxi in time of the flight\n",
    "- |-- SCHEDULED_ARRIVAL: integer (nullable = true) - The scheduled arrival time of the flight\n",
    "- |-- ARRIVAL_TIME: integer (nullable = true) - The actual arrival time of the flight\n",
    "- |-- ARRIVAL_DELAY: integer (nullable = true) - The arrival delay of the flight\n",
    "- |-- DIVERTED: integer (nullable = true) - Whether the flight was diverted or not\n",
    "- |-- CANCELLED: integer (nullable = true) - Whether the flight was cancelled or not\n",
    "- |-- CANCELLATION_REASON: string (nullable = true) - The reason the flight was cancelled\n",
    "- |-- AIR_SYSTEM_DELAY: integer (nullable = true) - The air system delay of the flight\n",
    "- |-- SECURITY_DELAY: integer (nullable = true) - The security delay of the flight\n",
    "- |-- AIRLINE_DELAY: integer (nullable = true) - The airline delay of the flight\n",
    "- |-- LATE_AIRCRAFT_DELAY: integer (nullable = true) - The late aircraft delay of the flight \n",
    "- |-- WEATHER_DELAY: integer (nullable = true) - The weather delay of the flight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading flights.csv.zip to /workspace/pyspark-airline-delay-classification\n",
      " 90%|████████████████████████████████████▉    | 172M/191M [00:00<00:00, 207MB/s]\n",
      "100%|█████████████████████████████████████████| 191M/191M [00:00<00:00, 206MB/s]\n",
      "Archive:  flights.csv.zip\n",
      "  inflating: flights.csv             \n"
     ]
    }
   ],
   "source": [
    "# download the dataset, extract, and remove compressed version\n",
    "!kaggle datasets download -d usdot/flight-delays -f \"flights.csv\"\n",
    "!unzip flights.csv.zip\n",
    "!rm flights.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initlize pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"airline-delay-analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to make Jupyter work with Gitpod\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DEPARTURE_TIME: integer (nullable = true)\n",
      " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- ARRIVAL_TIME: integer (nullable = true)\n",
      " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_REASON: string (nullable = true)\n",
      " |-- AIR_SYSTEM_DELAY: integer (nullable = true)\n",
      " |-- SECURITY_DELAY: integer (nullable = true)\n",
      " |-- AIRLINE_DELAY: integer (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
      " |-- WEATHER_DELAY: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read the data into a dataframe and print the schema\n",
    "df = spark.read.csv(\"flights.csv\", header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Add a column \"delayed\" which is 0 if DEPARTURE_DELAY is 0, 1 if DEPARTURE_DELAY is greater than 0 and -1 if DEPARTURE_DELAY is less than 0\n",
    "df = df.withColumn(\"DELAYED\", when(df[\"DEPARTURE_DELAY\"] == 0, 0).otherwise(when(df[\"DEPARTURE_DELAY\"] > 0, 1).otherwise(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data\n",
    "Drop the columns that we don't need or that we cannot predict before the flight\n",
    "\n",
    "Drop the following columns\n",
    "- |-- YEAR: integer (nullable = true) - Not needed since all flights are from the same year\n",
    "- |-- FLIGHT_NUMBER: integer (nullable = true) - Not needed since all planes have a unique flight number\n",
    "- |-- TAIL_NUMBER: string (nullable = true) - Not needed since all planes have a unique tail number\n",
    "- |-- DEPARTURE_TIME: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- DEPARTURE_DELAY: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- TAXI_OUT: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- WHEELS_OFF: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- ELAPSED_TIME: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- AIR_TIME: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- WHEELS_ON: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- TAXI_IN: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- ARRIVAL_TIME: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- ARRIVAL_DELAY: integer (nullable = true) - Not needed since we will only focus on the departure delay\n",
    "- |-- DIVERTED: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- CANCELLED: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- CANCELLATION_REASON: string (nullable = true) - Cannot know this before the flight\n",
    "- |-- AIR_SYSTEM_DELAY: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- SECURITY_DELAY: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- AIRLINE_DELAY: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- LATE_AIRCRAFT_DELAY: integer (nullable = true) - Cannot know this before the flight\n",
    "- |-- WEATHER_DELAY: integer (nullable = true) - Cannot know this before the flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- DELAYED: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(\"YEAR\", \"FLIGHT_NUMBER\", \"TAIL_NUMBER\", \"DEPARTURE_TIME\", \"DEPARTURE_DELAY\", \"TAXI_OUT\", \"WHEELS_OFF\", \"ELAPSED_TIME\", \"AIR_TIME\", \"WHEELS_ON\", \"TAXI_IN\", \"ARRIVAL_TIME\", \"ARRIVAL_DELAY\", \"DIVERTED\", \"CANCELLED\", \"CANCELLATION_REASON\", \"AIR_SYSTEM_DELAY\", \"SECURITY_DELAY\", \"AIRLINE_DELAY\", \"LATE_AIRCRAFT_DELAY\", \"WEATHER_DELAY\")\n",
    "\n",
    "# Our new schema\n",
    "# |-- MONTH: integer (nullable = true)\n",
    "# |-- DAY: integer (nullable = true)\n",
    "# |-- DAY_OF_WEEK: integer (nullable = true)\n",
    "# |-- AIRLINE: string (nullable = true)\n",
    "# |-- ORIGIN_AIRPORT: string (nullable = true)\n",
    "# |-- DESTINATION_AIRPORT: string (nullable = true)\n",
    "# |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
    "# |-- SCHEDULED_TIME: integer (nullable = true)\n",
    "# |-- DISTANCE: integer (nullable = true)\n",
    "# |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
    "# |-- DELAYED: integer (nullable = false)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:>                                                         (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5819073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Remove the rows that have null values\n",
    "df = df.dropna()\n",
    "\n",
    "# Print the number of rows\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for training\n",
    "\n",
    "We use StringIndexer to convert the categorical variables to numerical variables.\n",
    "\n",
    "We use VectorAssembler to convert the numerical variables to a feature vector (required by the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:>                                                         (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max categories: 629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Preparing the data\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "train, test = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Encode the categorical features using StringIndexer\n",
    "indexer = StringIndexer(inputCols=[\"AIRLINE\", \"ORIGIN_AIRPORT\", \"DESTINATION_AIRPORT\"], outputCols=[\"AIRLINE_INDEX\", \"ORIGIN_AIRPORT_INDEX\", \"DESTINATION_AIRPORT_INDEX\"])\n",
    "\n",
    "# Create the assembler\n",
    "assembler = VectorAssembler(inputCols=[\"MONTH\", \"DAY\", \"DAY_OF_WEEK\", \"AIRLINE_INDEX\", \"ORIGIN_AIRPORT_INDEX\", \"DESTINATION_AIRPORT_INDEX\", \"SCHEDULED_DEPARTURE\", \"SCHEDULED_TIME\", \"DISTANCE\", \"SCHEDULED_ARRIVAL\"], outputCol=\"features\")\n",
    "\n",
    "# Get the maximum number of all categorical features in the dataframe\n",
    "num_of_origins = df.select(\"ORIGIN_AIRPORT\").distinct().count()\n",
    "num_of_destinations = df.select(\"DESTINATION_AIRPORT\").distinct().count()\n",
    "num_of_carriers = df.select(\"AIRLINE\").distinct().count()\n",
    "max_num_of_categorical_features = max(num_of_origins, num_of_destinations, num_of_carriers)\n",
    "print(\"max categories:\", max_num_of_categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Classfier: Deision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/14 10:19:32 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 44.7 MiB so far)\n",
      "22/05/14 10:19:32 WARN BlockManager: Persisting block rdd_193_0 to disk instead.\n",
      "22/05/14 10:19:33 WARN MemoryStore: Not enough space to cache rdd_193_1 in memory! (computed 44.7 MiB so far)\n",
      "22/05/14 10:19:33 WARN BlockManager: Persisting block rdd_193_1 to disk instead.\n",
      "22/05/14 10:19:33 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 44.7 MiB so far)\n",
      "22/05/14 10:19:33 WARN BlockManager: Persisting block rdd_193_3 to disk instead.\n",
      "22/05/14 10:19:33 WARN MemoryStore: Not enough space to cache rdd_193_5 in memory! (computed 70.0 MiB so far)\n",
      "22/05/14 10:19:33 WARN BlockManager: Persisting block rdd_193_5 to disk instead.\n",
      "22/05/14 10:19:36 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 46.3 MiB so far)\n",
      "22/05/14 10:19:36 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 69.4 MiB so far)\n",
      "22/05/14 10:19:37 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 30.8 MiB so far)\n",
      "22/05/14 10:19:37 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 69.4 MiB so far)\n",
      "22/05/14 10:19:38 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 30.8 MiB so far)\n",
      "22/05/14 10:19:38 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 69.4 MiB so far)\n",
      "22/05/14 10:19:39 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 30.8 MiB so far)\n",
      "22/05/14 10:19:39 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 69.4 MiB so far)\n",
      "22/05/14 10:19:40 WARN MemoryStore: Not enough space to cache rdd_193_3 in memory! (computed 30.8 MiB so far)\n",
      "22/05/14 10:19:40 WARN MemoryStore: Not enough space to cache rdd_193_0 in memory! (computed 69.4 MiB so far)\n",
      "[Stage 88:=========>                                                (1 + 5) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Decision Tree) 0.6143093574619173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Use a Decision Tree Classifier to predict the delay\n",
    "# Split the data into training and testing sets\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "\n",
    "\n",
    "train, test = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create the classifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"DELAYED\", featuresCol=\"features\", maxBins=max_num_of_categorical_features)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[indexer, assembler, dt])\n",
    "\n",
    "# Create the grid\n",
    "# paramGrid = ParamGridBuilder().addGrid(dt.maxDepth, [2, 3, 4, 5, 6, 7, 8, 9, 10]).addGrid(dt.maxBins, [650, 750, 850, 950, 1050, 1150, 1250]).build()\n",
    "\n",
    "# Create the cross validator\n",
    "# cv = CrossValidator(estimator=pipeline, evaluator=MulticlassClassificationEvaluator(), estimatorParamMaps=paramGrid, numFolds=3)\n",
    "\n",
    "\n",
    "# Create the train validation split with the param grid\n",
    "# tvs = TrainValidationSplit(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=MulticlassClassificationEvaluator(), trainRatio=0.8)\n",
    "\n",
    "# Create the train validation split without the param grid\n",
    "# tvs = TrainValidationSplit(estimator=pipeline, evaluator=MulticlassClassificationEvaluator(), trainRatio=0.8)\n",
    "\n",
    "# Train the model using the pipeline\n",
    "model_basic = pipeline.fit(train)\n",
    "\n",
    "# Train the model using TrainValidationSplit\n",
    "# model = tvs.fit(train)\n",
    "\n",
    "# Train the model using CrossValidator\n",
    "# model = cv.fit(train)\n",
    "\n",
    "# Evaluate the models\n",
    "predictions_basic = model_basic.transform(test)\n",
    "\n",
    "# predictions_with_validation = tvs.fit(train).transform(test)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"DELAYED\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy (Decision Tree)\", evaluator.evaluate(predictions_basic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Classifer: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/14 10:20:23 WARN MemoryStore: Not enough space to cache rdd_255_5 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:23 WARN BlockManager: Persisting block rdd_255_5 to disk instead.\n",
      "22/05/14 10:20:23 WARN MemoryStore: Not enough space to cache rdd_255_4 in memory! (computed 64.5 MiB so far)\n",
      "22/05/14 10:20:23 WARN BlockManager: Persisting block rdd_255_4 to disk instead.\n",
      "22/05/14 10:20:23 WARN MemoryStore: Not enough space to cache rdd_255_3 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:23 WARN BlockManager: Persisting block rdd_255_3 to disk instead.\n",
      "22/05/14 10:20:23 WARN MemoryStore: Not enough space to cache rdd_255_0 in memory! (computed 64.5 MiB so far)\n",
      "22/05/14 10:20:23 WARN BlockManager: Persisting block rdd_255_0 to disk instead.\n",
      "22/05/14 10:20:23 WARN MemoryStore: Not enough space to cache rdd_255_2 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:23 WARN BlockManager: Persisting block rdd_255_2 to disk instead.\n",
      "22/05/14 10:20:23 WARN MemoryStore: Not enough space to cache rdd_255_1 in memory! (computed 64.5 MiB so far)\n",
      "22/05/14 10:20:23 WARN BlockManager: Persisting block rdd_255_1 to disk instead.\n",
      "22/05/14 10:20:26 WARN MemoryStore: Not enough space to cache rdd_255_2 in memory! (computed 8.0 MiB so far)\n",
      "22/05/14 10:20:26 WARN MemoryStore: Not enough space to cache rdd_255_5 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:26 WARN MemoryStore: Not enough space to cache rdd_255_3 in memory! (computed 18.9 MiB so far)\n",
      "22/05/14 10:20:27 WARN MemoryStore: Not enough space to cache rdd_255_1 in memory! (computed 100.8 MiB so far)\n",
      "22/05/14 10:20:28 WARN MemoryStore: Not enough space to cache rdd_255_5 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:28 WARN MemoryStore: Not enough space to cache rdd_255_3 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:29 WARN MemoryStore: Not enough space to cache rdd_255_2 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:29 WARN MemoryStore: Not enough space to cache rdd_255_1 in memory! (computed 64.5 MiB so far)\n",
      "22/05/14 10:20:31 WARN MemoryStore: Not enough space to cache rdd_255_1 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:31 WARN MemoryStore: Not enough space to cache rdd_255_2 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:31 WARN MemoryStore: Not enough space to cache rdd_255_5 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:31 WARN MemoryStore: Not enough space to cache rdd_255_3 in memory! (computed 64.5 MiB so far)\n",
      "22/05/14 10:20:33 WARN MemoryStore: Not enough space to cache rdd_255_5 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:33 WARN MemoryStore: Not enough space to cache rdd_255_1 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:33 WARN MemoryStore: Not enough space to cache rdd_255_3 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:34 WARN MemoryStore: Not enough space to cache rdd_255_2 in memory! (computed 64.5 MiB so far)\n",
      "22/05/14 10:20:37 WARN MemoryStore: Not enough space to cache rdd_255_3 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:37 WARN MemoryStore: Not enough space to cache rdd_255_2 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:37 WARN MemoryStore: Not enough space to cache rdd_255_5 in memory! (computed 42.5 MiB so far)\n",
      "22/05/14 10:20:37 WARN MemoryStore: Not enough space to cache rdd_255_1 in memory! (computed 64.5 MiB so far)\n",
      "[Stage 110:======================================>                  (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Random Forest) 0.6151872637727637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"DELAYED\", featuresCol=\"features\", numTrees=10, maxBins=max_num_of_categorical_features)\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer, assembler, rf])\n",
    "\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Evaluate the model and print the accuracy\n",
    "print(\"Accuracy (Random Forest)\", evaluator.evaluate(predictions))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
