{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading flights.csv.zip to /workspace/pyspark-airline-delay-classification\n",
      " 94%|█████████████████████████████████████▋  | 180M/191M [00:03<00:00, 36.1MB/s]\n",
      "100%|████████████████████████████████████████| 191M/191M [00:03<00:00, 50.4MB/s]\n",
      "Archive:  flights.csv.zip\n",
      "replace flights.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "# download the dataset, extract, and remove compressed version\n",
    "!kaggle datasets download -d usdot/flight-delays -f \"flights.csv\"\n",
    "!unzip flights.csv.zip\n",
    "!rm flights.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initlize pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"airline-delay-analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to make Jupyter work with Gitpod\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=========>                                                 (1 + 5) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DEPARTURE_TIME: integer (nullable = true)\n",
      " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- ARRIVAL_TIME: integer (nullable = true)\n",
      " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_REASON: string (nullable = true)\n",
      " |-- AIR_SYSTEM_DELAY: integer (nullable = true)\n",
      " |-- SECURITY_DELAY: integer (nullable = true)\n",
      " |-- AIRLINE_DELAY: integer (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
      " |-- WEATHER_DELAY: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read the data into a dataframe and print the schema\n",
    "df = spark.read.csv(\"flights.csv\", header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Add a column \"delayed\" which is 0 if DEPARTURE_DELAY is 0, 1 if DEPARTURE_DELAY is greater than 0 and -1 if DEPARTURE_DELAY is less than 0\n",
    "df = df.withColumn(\"DELAYED\", when(df[\"DEPARTURE_DELAY\"] == 0, 0).otherwise(when(df[\"DEPARTURE_DELAY\"] > 0, 1).otherwise(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Schema\n",
    "- |-- YEAR: integer (nullable = true) - The year of the flight\n",
    "- |-- MONTH: integer (nullable = true) - The month of the flight\n",
    "- |-- DAY: integer (nullable = true) - The day of the flight\n",
    "- |-- DAY_OF_WEEK: integer (nullable = true) - The day of the week of the flight\n",
    "- |-- AIRLINE: string (nullable = true) - The airline code of the flight\n",
    "- |-- FLIGHT_NUMBER: integer (nullable = true) - The flight number of the flight\n",
    "- |-- TAIL_NUMBER: string (nullable = true) - the tail number of the aircraft\n",
    "- |-- ORIGIN_AIRPORT: string (nullable = true) - The origin airport code of the flight\n",
    "- |-- DESTINATION_AIRPORT: string (nullable = true) - The destination airport code of the flight\n",
    "- |-- SCHEDULED_DEPARTURE: integer (nullable = true) - The scheduled departure time of the flight\n",
    "- |-- DEPARTURE_TIME: integer (nullable = true) - The actual departure time of the flight\n",
    "- |-- DEPARTURE_DELAY: integer (nullable = true) - The departure delay of the flight\n",
    "- |-- TAXI_OUT: integer (nullable = true) - The taxi out time of the flight\n",
    "- |-- WHEELS_OFF: integer (nullable = true) - The wheels off time of the flight\n",
    "- |-- SCHEDULED_TIME: integer (nullable = true) - The scheduled time of the flight\n",
    "- |-- ELAPSED_TIME: integer (nullable = true) - The elapsed time of the flight\n",
    "- |-- AIR_TIME: integer (nullable = true) - The air time of the flight\n",
    "- |-- DISTANCE: integer (nullable = true) - The distance between the origin and destination airports\n",
    "- |-- WHEELS_ON: integer (nullable = true) - The wheels on time of the flight\n",
    "- |-- TAXI_IN: integer (nullable = true) - The taxi in time of the flight\n",
    "- |-- SCHEDULED_ARRIVAL: integer (nullable = true) - The scheduled arrival time of the flight\n",
    "- |-- ARRIVAL_TIME: integer (nullable = true) - The actual arrival time of the flight\n",
    "- |-- ARRIVAL_DELAY: integer (nullable = true) - The arrival delay of the flight\n",
    "- |-- DIVERTED: integer (nullable = true) - Whether the flight was diverted or not\n",
    "- |-- CANCELLED: integer (nullable = true) - Whether the flight was cancelled or not\n",
    "- |-- CANCELLATION_REASON: string (nullable = true) - The reason the flight was cancelled\n",
    "- |-- AIR_SYSTEM_DELAY: integer (nullable = true) - The air system delay of the flight\n",
    "- |-- SECURITY_DELAY: integer (nullable = true) - The security delay of the flight\n",
    "- |-- AIRLINE_DELAY: integer (nullable = true) - The airline delay of the flight\n",
    "- |-- LATE_AIRCRAFT_DELAY: integer (nullable = true) - The late aircraft delay of the flight \n",
    "- |-- WEATHER_DELAY: integer (nullable = true) - The weather delay of the flight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- DELAYED: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "# Drop the columns that we don't need or that we cannot predict before the flight\n",
    "\n",
    "# Drop the following columns\n",
    "# |-- YEAR: integer (nullable = true) - Not needed since all flights are from the same year\n",
    "# |-- FLIGHT_NUMBER: integer (nullable = true) - Not needed since all planes have a unique flight number\n",
    "# |-- TAIL_NUMBER: string (nullable = true) - Not needed since all planes have a unique tail number\n",
    "# |-- DEPARTURE_TIME: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- DEPARTURE_DELAY: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- TAXI_OUT: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- WHEELS_OFF: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- ELAPSED_TIME: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- AIR_TIME: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- WHEELS_ON: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- TAXI_IN: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- ARRIVAL_TIME: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- ARRIVAL_DELAY: integer (nullable = true) - Not needed since we will only focus on the departure delay\n",
    "# |-- DIVERTED: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- CANCELLED: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- CANCELLATION_REASON: string (nullable = true) - Cannot know this before the flight\n",
    "# |-- AIR_SYSTEM_DELAY: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- SECURITY_DELAY: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- AIRLINE_DELAY: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- LATE_AIRCRAFT_DELAY: integer (nullable = true) - Cannot know this before the flight\n",
    "# |-- WEATHER_DELAY: integer (nullable = true) - Cannot know this before the flight\n",
    "\n",
    "df = df.drop(\"YEAR\", \"FLIGHT_NUMBER\", \"TAIL_NUMBER\", \"DEPARTURE_TIME\", \"DEPARTURE_DELAY\", \"TAXI_OUT\", \"WHEELS_OFF\", \"ELAPSED_TIME\", \"AIR_TIME\", \"WHEELS_ON\", \"TAXI_IN\", \"ARRIVAL_TIME\", \"ARRIVAL_DELAY\", \"DIVERTED\", \"CANCELLED\", \"CANCELLATION_REASON\", \"AIR_SYSTEM_DELAY\", \"SECURITY_DELAY\", \"AIRLINE_DELAY\", \"LATE_AIRCRAFT_DELAY\", \"WEATHER_DELAY\")\n",
    "\n",
    "# Our new schema\n",
    "# |-- MONTH: integer (nullable = true)\n",
    "# |-- DAY: integer (nullable = true)\n",
    "# |-- DAY_OF_WEEK: integer (nullable = true)\n",
    "# |-- AIRLINE: string (nullable = true)\n",
    "# |-- ORIGIN_AIRPORT: string (nullable = true)\n",
    "# |-- DESTINATION_AIRPORT: string (nullable = true)\n",
    "# |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
    "# |-- SCHEDULED_TIME: integer (nullable = true)\n",
    "# |-- DISTANCE: integer (nullable = true)\n",
    "# |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
    "# |-- DELAYED: integer (nullable = false)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5819073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Remove the rows that have null values\n",
    "df = df.dropna()\n",
    "\n",
    "# Print the number of rows\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Preparing the data\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "train, test = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Encode the categorical features using StringIndexer\n",
    "indexer = StringIndexer(inputCols=[\"AIRLINE\", \"ORIGIN_AIRPORT\", \"DESTINATION_AIRPORT\"], outputCols=[\"AIRLINE_INDEX\", \"ORIGIN_AIRPORT_INDEX\", \"DESTINATION_AIRPORT_INDEX\"])\n",
    "\n",
    "# Create the assembler\n",
    "assembler = VectorAssembler(inputCols=[\"MONTH\", \"DAY\", \"DAY_OF_WEEK\", \"AIRLINE_INDEX\", \"ORIGIN_AIRPORT_INDEX\", \"DESTINATION_AIRPORT_INDEX\", \"SCHEDULED_DEPARTURE\", \"SCHEDULED_TIME\", \"DISTANCE\", \"SCHEDULED_ARRIVAL\"], outputCol=\"features\")\n",
    "\n",
    "# Get the maximum number of all categorical features in the dataframe\n",
    "max_categories = df.select(\"AIRLINE\", \"ORIGIN_AIRPORT\", \"DESTINATION_AIRPORT\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Classfier: Deision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/13 14:13:36 WARN MemoryStore: Not enough space to cache rdd_73_2 in memory! (computed 44.7 MiB so far)\n",
      "22/05/13 14:13:36 WARN BlockManager: Persisting block rdd_73_2 to disk instead.\n",
      "22/05/13 14:13:36 WARN MemoryStore: Not enough space to cache rdd_73_4 in memory! (computed 44.7 MiB so far)\n",
      "22/05/13 14:13:36 WARN BlockManager: Persisting block rdd_73_4 to disk instead.\n",
      "22/05/13 14:13:37 WARN MemoryStore: Not enough space to cache rdd_73_5 in memory! (computed 70.0 MiB so far)\n",
      "22/05/13 14:13:37 WARN BlockManager: Persisting block rdd_73_5 to disk instead.\n",
      "22/05/13 14:13:37 WARN MemoryStore: Not enough space to cache rdd_73_1 in memory! (computed 44.7 MiB so far)\n",
      "22/05/13 14:13:37 WARN BlockManager: Persisting block rdd_73_1 to disk instead.\n",
      "22/05/13 14:13:40 WARN MemoryStore: Not enough space to cache rdd_73_2 in memory! (computed 46.3 MiB so far)\n",
      "22/05/13 14:13:40 WARN MemoryStore: Not enough space to cache rdd_73_1 in memory! (computed 46.3 MiB so far)\n",
      "22/05/13 14:13:41 WARN MemoryStore: Not enough space to cache rdd_73_1 in memory! (computed 30.8 MiB so far)\n",
      "22/05/13 14:13:41 WARN MemoryStore: Not enough space to cache rdd_73_2 in memory! (computed 69.4 MiB so far)\n",
      "22/05/13 14:13:42 WARN MemoryStore: Not enough space to cache rdd_73_1 in memory! (computed 30.8 MiB so far)\n",
      "22/05/13 14:13:43 WARN MemoryStore: Not enough space to cache rdd_73_2 in memory! (computed 69.4 MiB so far)\n",
      "22/05/13 14:13:44 WARN MemoryStore: Not enough space to cache rdd_73_1 in memory! (computed 30.8 MiB so far)\n",
      "22/05/13 14:13:44 WARN MemoryStore: Not enough space to cache rdd_73_2 in memory! (computed 69.4 MiB so far)\n",
      "22/05/13 14:13:46 WARN MemoryStore: Not enough space to cache rdd_73_1 in memory! (computed 30.8 MiB so far)\n",
      "22/05/13 14:13:46 WARN MemoryStore: Not enough space to cache rdd_73_2 in memory! (computed 46.3 MiB so far)\n",
      "[Stage 37:===================>                                      (2 + 4) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (No Train Validation) 0.6134423842584504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Use a Decision Tree Classifier to predict the delay\n",
    "# Split the data into training and testing sets\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "\n",
    "\n",
    "train, test = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create the classifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"DELAYED\", featuresCol=\"features\", maxBins=max_categories)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[indexer, assembler, dt])\n",
    "\n",
    "# Create the grid\n",
    "# paramGrid = ParamGridBuilder().addGrid(dt.maxDepth, [2, 3, 4, 5, 6, 7, 8, 9, 10]).addGrid(dt.maxBins, [650, 750, 850, 950, 1050, 1150, 1250]).build()\n",
    "\n",
    "# Create the cross validator\n",
    "# cv = CrossValidator(estimator=pipeline, evaluator=MulticlassClassificationEvaluator(), estimatorParamMaps=paramGrid, numFolds=3)\n",
    "\n",
    "\n",
    "# Create the train validation split with the param grid\n",
    "# tvs = TrainValidationSplit(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=MulticlassClassificationEvaluator(), trainRatio=0.8)\n",
    "\n",
    "# Create the train validation split without the param grid\n",
    "# tvs = TrainValidationSplit(estimator=pipeline, evaluator=MulticlassClassificationEvaluator(), trainRatio=0.8)\n",
    "\n",
    "# Train the model using the pipeline\n",
    "model_basic = pipeline.fit(train)\n",
    "\n",
    "# Train the model using TrainValidationSplit\n",
    "# model = tvs.fit(train)\n",
    "\n",
    "# Train the model using CrossValidator\n",
    "# model = cv.fit(train)\n",
    "\n",
    "# Evaluate the models\n",
    "predictions_basic = model_basic.transform(test)\n",
    "\n",
    "# predictions_with_validation = tvs.fit(train).transform(test)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"DELAYED\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy (Decision Tree)\", evaluator.evaluate(predictions_basic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Classifer: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/13 14:16:46 WARN MemoryStore: Not enough space to cache rdd_165_1 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:46 WARN BlockManager: Persisting block rdd_165_1 to disk instead.\n",
      "22/05/13 14:16:46 WARN MemoryStore: Not enough space to cache rdd_165_2 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:46 WARN BlockManager: Persisting block rdd_165_2 to disk instead.\n",
      "22/05/13 14:16:47 WARN MemoryStore: Not enough space to cache rdd_165_3 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:47 WARN BlockManager: Persisting block rdd_165_3 to disk instead.\n",
      "22/05/13 14:16:47 WARN MemoryStore: Not enough space to cache rdd_165_4 in memory! (computed 64.5 MiB so far)\n",
      "22/05/13 14:16:47 WARN BlockManager: Persisting block rdd_165_4 to disk instead.\n",
      "22/05/13 14:16:47 WARN MemoryStore: Not enough space to cache rdd_165_5 in memory! (computed 64.5 MiB so far)\n",
      "22/05/13 14:16:47 WARN BlockManager: Persisting block rdd_165_5 to disk instead.\n",
      "22/05/13 14:16:51 WARN MemoryStore: Not enough space to cache rdd_165_2 in memory! (computed 18.9 MiB so far)\n",
      "22/05/13 14:16:51 WARN MemoryStore: Not enough space to cache rdd_165_4 in memory! (computed 100.8 MiB so far)\n",
      "22/05/13 14:16:51 WARN MemoryStore: Not enough space to cache rdd_165_1 in memory! (computed 64.5 MiB so far)\n",
      "22/05/13 14:16:51 WARN MemoryStore: Not enough space to cache rdd_165_3 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:53 WARN MemoryStore: Not enough space to cache rdd_165_4 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:53 WARN MemoryStore: Not enough space to cache rdd_165_2 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:53 WARN MemoryStore: Not enough space to cache rdd_165_3 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:53 WARN MemoryStore: Not enough space to cache rdd_165_1 in memory! (computed 64.5 MiB so far)\n",
      "22/05/13 14:16:55 WARN MemoryStore: Not enough space to cache rdd_165_1 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:55 WARN MemoryStore: Not enough space to cache rdd_165_3 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:55 WARN MemoryStore: Not enough space to cache rdd_165_4 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:55 WARN MemoryStore: Not enough space to cache rdd_165_2 in memory! (computed 64.5 MiB so far)\n",
      "22/05/13 14:16:59 WARN MemoryStore: Not enough space to cache rdd_165_2 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:59 WARN MemoryStore: Not enough space to cache rdd_165_4 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:59 WARN MemoryStore: Not enough space to cache rdd_165_1 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:16:59 WARN MemoryStore: Not enough space to cache rdd_165_3 in memory! (computed 64.5 MiB so far)\n",
      "22/05/13 14:17:03 WARN MemoryStore: Not enough space to cache rdd_165_2 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:17:03 WARN MemoryStore: Not enough space to cache rdd_165_1 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:17:03 WARN MemoryStore: Not enough space to cache rdd_165_3 in memory! (computed 42.5 MiB so far)\n",
      "22/05/13 14:17:03 WARN MemoryStore: Not enough space to cache rdd_165_4 in memory! (computed 64.5 MiB so far)\n",
      "[Stage 67:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Random Forest) 0.6158698537274945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"DELAYED\", featuresCol=\"features\", numTrees=10, maxBins=max_categories)\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer, assembler, rf])\n",
    "\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Evaluate the model and print the accuracy\n",
    "print(\"Accuracy (Random Forest)\", evaluator.evaluate(predictions))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
