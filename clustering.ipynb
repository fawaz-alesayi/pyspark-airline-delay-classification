{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shapely in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (1.8.2)\n"
     ]
    }
   ],
   "source": [
    "# Install shapely to deal with geospatial data\n",
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2020-04-01_performance_mobile_tiles.parquet.zip to /workspace/pyspark-airline-delay-classification\n",
      " 94%|█████████████████████████████████████▋  | 241M/256M [00:05<00:00, 40.2MB/s]\n",
      "100%|████████████████████████████████████████| 256M/256M [00:05<00:00, 51.1MB/s]\n",
      "Archive:  2020-04-01_performance_mobile_tiles.parquet.zip\n",
      "replace 2020-04-01_performance_mobile_tiles.parquet? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d dhruvildave/ookla-internet-speed-dataset -f \"2020-q2/2020-04-01_performance_mobile_tiles.parquet\"\n",
    "!unzip 2020-04-01_performance_mobile_tiles.parquet.zip\n",
    "!rm 2020-04-01_performance_mobile_tiles.parquet.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initlize pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"internet-analysis-clustering\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to make Jupyter work with Gitpod\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- quadkey: string (nullable = true)\n",
      " |-- tile: string (nullable = true)\n",
      " |-- avg_d_kbps: long (nullable = true)\n",
      " |-- avg_u_kbps: long (nullable = true)\n",
      " |-- avg_lat_ms: long (nullable = true)\n",
      " |-- tests: long (nullable = true)\n",
      " |-- devices: long (nullable = true)\n",
      "\n",
      "+----------------+--------------------+----------+----------+----------+-----+-------+\n",
      "|         quadkey|                tile|avg_d_kbps|avg_u_kbps|avg_lat_ms|tests|devices|\n",
      "+----------------+--------------------+----------+----------+----------+-----+-------+\n",
      "|1203022122320032|POLYGON((24.09301...|     28772|      3165|        34|    8|      1|\n",
      "|0313113213321131|POLYGON((-1.49963...|     20782|     10180|        54|    2|      2|\n",
      "|1221210331312333|POLYGON((30.88806...|     22690|     22416|       449|    6|      2|\n",
      "|1200312211223323|POLYGON((18.00109...|     54493|      4635|        21|    2|      2|\n",
      "|0302233220203221|POLYGON((-81.5130...|     90669|      6576|        21|    1|      1|\n",
      "+----------------+--------------------+----------+----------+----------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the data into a dataframe and print the schema\n",
    "df = spark.read.parquet(\"2020-04-01_performance_mobile_tiles.parquet\")\n",
    "df.printSchema()\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "\n",
    "@udf(returnType=DoubleType())\n",
    "def longitude(polygon: str):\n",
    "    return wkt.loads(polygon).centroid.x\n",
    "\n",
    "@udf(returnType=DoubleType())\n",
    "def latitude(polygon):\n",
    "    return wkt.loads(polygon).centroid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+----------+----------+----------+-----+-------+------------------+------------------+\n",
      "|         quadkey|                tile|avg_d_kbps|avg_u_kbps|avg_lat_ms|tests|devices|         longitude|          latitude|\n",
      "+----------------+--------------------+----------+----------+----------+-----+-------+------------------+------------------+\n",
      "|1203022122320032|POLYGON((24.09301...|     28772|      3165|        34|    8|      1| 24.09576416015625| 49.88224742799456|\n",
      "|0313113213321131|POLYGON((-1.49963...|     20782|     10180|        54|    2|      2| -1.49688720703125|52.953602268373295|\n",
      "|1221210331312333|POLYGON((30.88806...|     22690|     22416|       449|    6|      2| 30.89080810546875|29.919232776382895|\n",
      "|1200312211223323|POLYGON((18.00109...|     54493|      4635|        21|    2|      2| 18.00384521484375|59.356996008027856|\n",
      "|0302233220203221|POLYGON((-81.5130...|     90669|      6576|        21|    1|      1|-81.51031494140625|41.317012752730506|\n",
      "+----------------+--------------------+----------+----------+----------+-----+-------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- quadkey: string (nullable = true)\n",
      " |-- tile: string (nullable = true)\n",
      " |-- avg_d_kbps: long (nullable = true)\n",
      " |-- avg_u_kbps: long (nullable = true)\n",
      " |-- avg_lat_ms: long (nullable = true)\n",
      " |-- tests: long (nullable = true)\n",
      " |-- devices: long (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adds two columns: longitude and latitude\n",
    "df = df.withColumn(\"longitude\", longitude(df.tile))\n",
    "df = df.withColumn(\"latitude\", latitude(df.tile))\n",
    "\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- avg_d_kbps: long (nullable = true)\n",
      " |-- avg_u_kbps: long (nullable = true)\n",
      " |-- avg_lat_ms: long (nullable = true)\n",
      " |-- tests: long (nullable = true)\n",
      " |-- devices: long (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4075861"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the \"quadkey\" and \"tile\" columns\n",
    "df = df.drop(\"tile\")\n",
    "df = df.drop(\"quadkey\")\n",
    "df.printSchema()\n",
    "\n",
    "\n",
    "# Drop null values\n",
    "df = df.dropna()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"avg_d_kbps\", \"avg_u_kbps\", \"tests\", \"devices\", \"latitude\", \"longitude\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/13 21:01:26 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:29 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:30 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:31 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:32 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:33 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:36 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:41 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:40 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:38 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:45 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:44 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:44 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:42 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:52 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:52 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:56 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n",
      "22/05/13 21:01:55 WARN TaskMemoryManager: Failed to allocate a page (4194304 bytes), try again.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "# Import pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "kmeans = KMeans().setK(3)\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, kmeans])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(df)\n",
    "\n",
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "print(\"Silhouette with squared euclidean distance = \", evaluator.evaluate(predictions))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
