{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install shapely to deal with geospatial data\n",
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d dhruvildave/ookla-internet-speed-dataset -f \"2020-q2/2020-04-01_performance_mobile_tiles.parquet\"\n",
    "!unzip 2020-04-01_performance_mobile_tiles.parquet.zip\n",
    "!rm 2020-04-01_performance_mobile_tiles.parquet.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initlize pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"internet-analysis-clustering\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to make Jupyter work with Gitpod\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe_connected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a dataframe and print the schema\n",
    "df = spark.read.parquet(\"2020-04-01_performance_mobile_tiles.parquet\")\n",
    "df.printSchema()\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "\n",
    "@udf(returnType=DoubleType())\n",
    "def longitude(polygon: str):\n",
    "    return wkt.loads(polygon).centroid.x\n",
    "\n",
    "@udf(returnType=DoubleType())\n",
    "def latitude(polygon):\n",
    "    return wkt.loads(polygon).centroid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds two columns: longitude and latitude\n",
    "df = df.withColumn(\"longitude\", longitude(df.tile))\n",
    "df = df.withColumn(\"latitude\", latitude(df.tile))\n",
    "\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"quadkey\" and \"tile\" columns\n",
    "df = df.drop(\"tile\")\n",
    "df = df.drop(\"quadkey\")\n",
    "df.printSchema()\n",
    "\n",
    "\n",
    "# Drop null values\n",
    "df = df.dropna()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data\n",
    "\n",
    "As usual, we generate the features vector using VectorAssembler\n",
    "\n",
    "Then we apply MinMax Normalization using MinMaxNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"avg_d_kbps\", \"avg_u_kbps\", \"tests\", \"devices\", \"latitude\", \"longitude\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "# Import pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "kmeans = KMeans().setK(3)\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, kmeans])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(df)\n",
    "\n",
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "print(\"Silhouette with squared euclidean distance = \", evaluator.evaluate(predictions))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
